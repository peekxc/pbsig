{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Circle optimization\n",
        "format: html\n",
        "editor:\n",
        "  render-on-save: true\n",
        "---"
      ],
      "id": "e79e125f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from splex import *\n",
        "from pbsig import * \n",
        "from pbsig.linalg import * \n",
        "from pbsig.vis import figure_complex\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.layouts import row\n",
        "output_notebook(verbose=False)"
      ],
      "id": "2ebf80d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a noisy circle. For any choice of fixed radius $\\epsilon \\in \\mathbb{R}_+$, we can construct a rips filtration $\\mathcal{R}(X; \\epsilon)$. For example:\n"
      ],
      "id": "73d9330f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.vis import *\n",
        "np.random.seed(1234)\n",
        "theta = np.linspace(0, 2*np.pi, 8, endpoint=False)\n",
        "circle = np.c_[np.sin(theta), np.cos(theta)]\n",
        "\n",
        "eps_radius = 1.0\n",
        "R = rips_filtration(circle, 1.0, p=2)\n",
        "\n",
        "## Plot the circle + noise \n",
        "p = figure(width=300, height=300, match_aspect=True)\n",
        "p.scatter(*circle.T, color=\"blue\", size=12)\n",
        "\n",
        "show(row(p, figure_complex(R, circle)))"
      ],
      "id": "354235f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The homology of the rips complex is highly dependent on the scale parameter $\\epsilon$. This shows that homology, in general, is not scale-invariant. To counter this, the typical approach is to vary $\\epsilon \\in [0, +\\infty)$ and track the changes in the homology groups. Homology groups that seem to persist for over long contiguous subsets of $[0, +\\infty)$ are thought to contain highly persistent cycles, i.e. homeomorphic cycles that are stable with respect to changes in the geometry. This is a bit of a misnomer, as the actual \"cycles\" generating the homology groups change quite often; indeed, each inclusion map $K_{i-1} \\hookrightarrow K_{i}$ induces an entirely new coset.\n",
        "\n",
        "Persistence is often summarized with a persistence diagram.\n"
      ],
      "id": "1d6513f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.persistence import ph\n",
        "max_radius = 3.0\n",
        "K = rips_filtration(circle, max_radius, p=2)\n",
        "dgms = ph(K, engine=\"dionysus\")\n",
        "dgm = dgms[1]\n",
        "show(figure_dgm(dgm))"
      ],
      "id": "674becd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing a different parameter\n",
        "\n",
        "Indeed, suppose we scale our circle by some scaling factor $\\alpha \\in [0,1]$, fixing $\\epsilon$ arbitrarily.\n"
      ],
      "id": "2a0e4418"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.vis import bin_color\n",
        "max_scale = 2.0\n",
        "alpha_family = np.linspace(0, max_scale, 100)\n",
        "vine = np.c_[alpha_family*dgm[\"birth\"], alpha_family*dgm[\"death\"]]\n",
        "\n",
        "p = figure_dgm()\n",
        "p.scatter(vine[:,0],vine[:,1], color=bin_color(alpha_family, \"turbo\"))\n",
        "# p.lookup(name)\n",
        "show(p)\n",
        "\n",
        "\n",
        "# from bokeh.layouts import gridplot\n",
        "# from itertools import product\n",
        "# nr, nc, r = 2, 6, 0.5 # num rows, num columns, radius \n",
        "# max_scale = 3.0\n",
        "# F = lambda alpha: (alpha*circle, rips_filtration(alpha*circle, r, p=2))\n",
        "# plots = [[None]*nc for r in range(nr)]\n",
        "# for alpha, (i,j) in zip(np.linspace(0.0, max_scale*r, nr*nc), product(range(nr), range(nc))):\n",
        "#   X, R = F(alpha)\n",
        "#   plots[i][j] = figure_complex(R, X, width=100, height=100, x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r))\n",
        "# show(gridplot(plots))"
      ],
      "id": "f5c33d25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have essentially the same effect, but in reverse: at first the complex is the full $n$-simplex, collapsed to trivial point in its embedding. As the complex expands, it changes from being a disk (trivial $H_1$) to a circle (non-trivial $H_1$) to $n$ disconnected points (trivial $H_1$). Essentially, rather than having an $\\epsilon$-parameterized filtration over a fixed point cloud, we have an $\\alpha$-parameterized family of rips filtrations $\\{ \\mathcal{R}_{\\epsilon}(\\alpha) \\}_{\\alpha \\in A}$ of varying size but fixed filter.\n",
        "\n",
        "<!-- Suppose one is interested in finding the interval wherein the cycle generating the single homology group $H_1$ is the most \"persistent\" in $\\alpha$. We could build a filtration in reverse to get inclusions... -->\n"
      ],
      "id": "1a079eb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.vis import plot_dgm, figure_dgm\n",
        "from pbsig.persistence import ph \n",
        "# X, R = F(0.50)\n",
        "# dgm = ph(R, engine=\"dionysus\")[1]\n",
        "# plot_dgm(dgm)\n",
        "\n",
        "plots = [[None]*nc for r in range(nr)]\n",
        "for alpha, (i,j) in zip(np.linspace(0.0, max_scale*r, nr*nc), product(range(nr), range(nc))):\n",
        "  X, R = F(alpha)\n",
        "  dgm = ph(R, engine=\"dionysus\")\n",
        "  dgm = dgm[1] if 1 in dgm.keys() else np.empty((0,2),dtype=[('birth', 'f4'), ('death', 'f4')])\n",
        "  # figure_complex(R, X, width=100, height=100, x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r))\n",
        "  plots[i][j] = figure_dgm(dgm, width=100, height=100) # x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r)\n",
        "  plots[i][j].title = None\n",
        "  plots[i][j].xaxis.axis_label = None\n",
        "  plots[i][j].yaxis.axis_label = None\n",
        "  # plots[i][j].xaxis.visible = False\n",
        "show(gridplot(plots))"
      ],
      "id": "8b237665",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe we have a few \"phase changes\" that occur here. Initially, there is no $H_1$ class. As the the complex expands beyond the trivial point, a point appears representing the aforementioned cycle. Since the persistence diagram is stable, we know this point must appear first on the diagonal---it then travels further from the diagonal until the cycle is broken apart. In this situation, it becomes an *essential class*; we have not expanded the rips complex to a large enough $\\epsilon$ to see triangles close up the cycle. The birth of the cycle grows infinitely as $\\alpha \\to \\infty$.\n",
        "\n",
        "Suppose we wanted to determine the choices of $\\alpha$ where this cycle existed. We can peek at these via a set of multiplicity queries:\n"
      ],
      "id": "3d196541"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.betti import mu_query\n",
        "R = (0.5, 1.0, 1.5, 2.0)\n",
        "S = simplicial_complex(faces(SimplexTree([np.arange(8)]), 2))\n",
        "Q = [mu_query(S, R=R, f=flag_weight(alpha*circle), p=1, normed=False) for alpha in alpha_family]\n",
        "\n",
        "mult_H1 = [mu() for mu in Q]\n",
        "p = figure(\n",
        "  width=350, height=200, \n",
        "  title=f\"Circle multiplicities for R={R}\", x_axis_label=\"alpha (scaling factor)\", y_axis_label=\"multiplicity\"\n",
        ")\n",
        "p.step(alpha_family, np.array(mult_H1, dtype=int))\n",
        "p.yaxis.minor_tick_line_alpha = 0\n",
        "show(p)"
      ],
      "id": "6efe1030",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Equivalently, we can amortize the cost of creating so many matrices by re-using the results from previous computations.\n"
      ],
      "id": "9e816cb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.betti import MuFamily\n",
        "F = [flag_weight(alpha*circle) for alpha in alpha_family]\n",
        "mu_f = MuFamily(S, family=F, p=1, form=\"array\")\n",
        "mu_f.precompute(R=R, progress=True)\n",
        "\n",
        "p = figure(\n",
        "  width=350, height=200, \n",
        "  title=f\"Circle multiplicities for R={R}\", x_axis_label=\"alpha (scaling factor)\", y_axis_label=\"multiplicity\"\n",
        ")\n",
        "p.step(alpha_thresholds, np.array(mu_f(smoothing=None), dtype=int))\n",
        "p.yaxis.minor_tick_line_alpha = 0\n",
        "show(p)"
      ],
      "id": "25db5ea0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the constitutive terms that make up this multiplicity queries\n"
      ],
      "id": "0347bd11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p = figure(\n",
        "  width=350, height=200, \n",
        "  title=f\"Circle multiplicities for R={R}\", \n",
        "  x_axis_label=\"alpha (scaling factor)\", \n",
        "  y_axis_label=\"Constititive ranks\"\n",
        ")\n",
        "mu_terms = mu_f(smoothing=None, terms=True).T\n",
        "p.step(alpha_thresholds, mu_terms[:,0], line_color=\"red\")\n",
        "p.step(alpha_thresholds, -mu_terms[:,1], line_color=\"green\")\n",
        "p.step(alpha_thresholds, -mu_terms[:,2], line_color=\"blue\")\n",
        "p.step(alpha_thresholds, mu_terms[:,3], line_color=\"orange\")\n",
        "p.step(alpha_thresholds, mu_f(smoothing=None), line_color=\"black\")\n",
        "p.yaxis.minor_tick_line_alpha = 0\n",
        "show(p)"
      ],
      "id": "992aed96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's look at a continuous relaxation of both the multiplicity function and its constitituive terms.\n"
      ],
      "id": "f538aec9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## constituive terms\n",
        "figures = [[] for i in range(4)]\n",
        "for w, normed in [(0.0,False), (0.0,True), (0.30,False), (0.30,True)]:\n",
        "  mu_f.precompute(R=R, w=w, normed=normed, progress=True)\n",
        "  mu_terms = mu_f(smoothing=None, terms=True).T\n",
        "  mu_terms_nuclear = mu_f(smoothing=False, terms=True).T\n",
        "  mu_terms_sgn_approx = mu_f(smoothing=sgn_approx(eps=1e-1, p=1.5), terms=True).T\n",
        "  for i in range(4):\n",
        "    p = figure(\n",
        "      width=200, height=200, \n",
        "      title=f\"w:{w}, normed:{normed}\", x_axis_label=\"alpha (scaling factor)\", y_axis_label=\"multiplicity\"\n",
        "    )\n",
        "    p.yaxis.minor_tick_line_alpha = 0\n",
        "    p.line(alpha_thresholds, mu_terms_nuclear[:,i], line_color = \"orange\", line_width=2.0)\n",
        "    p.line(alpha_thresholds, mu_terms_sgn_approx[:,i], line_color = \"blue\",  line_width=1.5)\n",
        "    p.step(alpha_thresholds, mu_terms[:,i], line_color = \"black\", line_width=1.0)\n",
        "    figures[i].append(p)\n",
        "\n",
        "show(row([column(f) for f in figures]))"
      ],
      "id": "961a3bba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The weighted combinatorial laplacian is unstable whenever $w > 0$, due to the fact that $1/\\epsilon$ can produce arbitrarily large values as $\\epsilon \\to 0^+$. This is not a problem for the normalized laplacian, as the spectrum is always bounded in the range $[0, p+2]$.\n",
        "\n",
        "**TAKEAWAY**: If $w > 0$, you need degree normalization to stabilize the spectrum. Though the nuclear norm is at times quite similar to the rank, it can also differ greatly.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "From now on, let's only consider the normalized weighted combinatorial laplacian. Let's look at the effect of w\n"
      ],
      "id": "bb1d0992"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "W = [0.0, 0.20, 0.40, 0.60, 0.80]\n",
        "fig_kwargs = dict(width=200, height=150)\n",
        "\n",
        "## Try varying epsilon in [1e-1, 100] to see interpolation of behavior\n",
        "figures = [[] for i in range(len(W))]\n",
        "for i,w in enumerate(W):\n",
        "  mu_f.precompute(R=R, w=w, normed=True, progress=True)\n",
        "  for j,ef in enumerate([None, sgn_approx(eps=1e-1, p=1.2), False]):\n",
        "    mu_terms = mu_f(smoothing=ef, terms=True).T\n",
        "    p = figure(**(fig_kwargs | dict(title=f\"w:{w}, smooth:{j}\")))\n",
        "    p.line(alpha_thresholds, mu_terms[:,0], line_color=\"red\")\n",
        "    p.line(alpha_thresholds, -mu_terms[:,1], line_color=\"green\")\n",
        "    p.line(alpha_thresholds, -mu_terms[:,2], line_color=\"blue\")\n",
        "    p.line(alpha_thresholds, mu_terms[:,3], line_color=\"orange\")\n",
        "    p.line(alpha_thresholds, mu_terms.sum(axis=1), line_color=\"black\")\n",
        "    p.yaxis.minor_tick_line_alpha = 0\n",
        "    figures[i].append(p)\n",
        "\n",
        "show(column([row(f) for f in figures]))"
      ],
      "id": "4b966d5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The nuclear norm not only causes a spurious modes, it effectively removes the existing maximizer. Changing `w` has the effect of smoothing the objective and expanding the feasible set when appropriately chosen and the sgn approximation is used, whereas seemingly has neglible on the nuclear norm.\n",
        "\n",
        "Let's evaluate the Moreau envelope on the nuclear norm.\n"
      ],
      "id": "aea0af4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w = 10000.35\n",
        "mu_f.precompute(R=R, w=w, normed=True, progress=True) "
      ],
      "id": "daebaacf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.linalg import *\n",
        "from pbsig.utility import *\n",
        "\n",
        "\n",
        "mu_terms = mu_f(smoothing=True, terms=True).T\n",
        "mu_mats = [mu_query_mat(S=S, R=np.append(R, w), f=f, p=1, form = 'array', normed=True) \n",
        "           for f in mu_f.family]\n",
        "me = lambda M, t: prox_nuclear(M, t)[1]\n",
        "\n",
        "t = 0.50\n",
        "mu_moreau = [[] for i in range(4)]\n",
        "for M1, M2, M3, M4 in progressbar(mu_mats):\n",
        "  mu_moreau[0].append(me(M1, t))\n",
        "  mu_moreau[1].append(-me(M2, t))\n",
        "  mu_moreau[2].append(-me(M3, t))\n",
        "  mu_moreau[3].append(me(M4, t))\n",
        "mu_moreau = np.array(mu_moreau).T\n",
        "\n",
        "magnitudes = abs(mu_terms).sum(axis=1)\n",
        "magnitudes = np.isclose(magnitudes, 0.0).astype(int)\n",
        "feasible = np.flatnonzero(np.diff(magnitudes) != 0.0)\n",
        "\n",
        "p = figure(**(fig_kwargs | dict(title=f\"w:{w}, smooth:{j}\")))\n",
        "p.line(alpha_thresholds, mu_terms.sum(axis=1), line_color=\"black\")\n",
        "p.line(alpha_thresholds, mu_moreau.sum(axis=1), line_color=\"black\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.yaxis.minor_tick_line_alpha = 0\n",
        "show(p)"
      ],
      "id": "036b604e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import line_profiler\n",
        "\n",
        "profile = line_profiler.LineProfiler()\n",
        "profile.add_function(mu_f.precompute)\n",
        "profile.enable_by_count()\n",
        "mu_f.precompute(R=R, w=w, normed=True, progress=True) \n",
        "profile.print_stats(output_unit=1e-3)"
      ],
      "id": "c3372da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def moreau_loss(x: ArrayLike, eps: float, p: float = 1.0, t: float = 1.0):\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "    x: ndarray, spmatrix, or LinearOperator\n",
        "    t: proximal scaling operator \n",
        "  \"\"\"\n",
        "  from scipy.sparse import spmatrix\n",
        "  from scipy.optimize import minimize\n",
        "  if isinstance(x, np.ndarray) and all(np.ravel(x == 0)):\n",
        "    return 0\n",
        "  elif isinstance(x, spmatrix) and len(x.data) == 0:\n",
        "    return 0\n",
        "  sf = sgn_approx(eps=eps, p=p)  \n",
        "  x_ew = np.linalg.eigvalsh(x)\n",
        "  def sgn_approx_cost(ew_hat: ArrayLike, t: float):\n",
        "    return sum(sf(ew_hat)) + (1/(t*2)) * np.linalg.norm(sf(ew_hat) - sf(x_ew))**2\n",
        "  w = minimize(sgn_approx_cost, x0=x_ew, args=(t), tol=1e-15, method=\"Powell\")\n",
        "  if w.status != 0:\n",
        "    import warnings\n",
        "    warnings.warn(\"Did not converge to sign vector prox\")\n",
        "  ew = w.x if w.status == 0 else x_ew\n",
        "  return sgn_approx_cost(ew, t)\n",
        "\n",
        "\n",
        "t, eps = 0.80, 1e-1\n",
        "mu_moreau = [[] for i in range(4)]\n",
        "for M1, M2, M3, M4 in mu_mats:\n",
        "  mu_moreau[0].append(moreau_loss(M1.todense(), eps=eps, p=1.5, t=t))\n",
        "  mu_moreau[1].append(-moreau_loss(M2.todense(), eps=eps, p=1.5, t=t))\n",
        "  mu_moreau[2].append(-moreau_loss(M3.todense(), eps=eps, p=1.5, t=t))\n",
        "  mu_moreau[3].append(moreau_loss(M4.todense(), eps=eps, p=1.5, t=t))\n",
        "mu_moreau = np.array(mu_moreau).T\n",
        "\n",
        "p = figure(**(fig_kwargs | dict(title=f\"w:{w}, t:{t}, eps:{eps}\")))\n",
        "p.line(alpha_thresholds, mu_terms[:,0], line_color=\"red\")\n",
        "p.line(alpha_thresholds, mu_moreau[:,0], line_color=\"red\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, -mu_terms[:,1], line_color=\"green\")\n",
        "p.line(alpha_thresholds, -mu_moreau[:,1], line_color=\"green\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, -mu_terms[:,2], line_color=\"blue\")\n",
        "p.line(alpha_thresholds, -mu_moreau[:,2], line_color=\"blue\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, mu_terms[:,3], line_color=\"orange\")\n",
        "p.line(alpha_thresholds, mu_moreau[:,3], line_color=\"orange\", line_dash=\"dotted\", line_width=1.5)\n",
        "q = figure(**(fig_kwargs | dict(title=f\"w:{w}, t:{t}, eps:{eps}\")))\n",
        "q.line(alpha_thresholds, mu_terms.sum(axis=1), line_color=\"black\")\n",
        "p.line(alpha_thresholds, mu_terms.sum(axis=1), line_color=\"black\")\n",
        "q.line(alpha_thresholds, mu_moreau.sum(axis=1), line_color=\"black\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, mu_moreau.sum(axis=1), line_color=\"black\", line_dash=\"dotted\", line_width=1.5)\n",
        "q.yaxis.minor_tick_line_alpha = 0\n",
        "show(row(p, q))"
      ],
      "id": "878d58b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.linalg import *\n",
        "w = 0.35\n",
        "mu_f.precompute(R=R, w=w, normed=True, progress=True) \n",
        "mu_terms = mu_f(smoothing=True, terms=True).T\n",
        "mu_mats = [mu_query_mat(S=S, R=R, f=f, p=1, form = 'array', normed=True, w=w) for f in mu_f.family]\n",
        "me = lambda M, t: prox_nuclear(M, t)[1]\n",
        "\n",
        "t = 5.0\n",
        "mu_moreau = [[] for i in range(4)]\n",
        "for M1, M2, M3, M4 in mu_mats:\n",
        "  mu_moreau[0].append(me(M1, t))\n",
        "  mu_moreau[1].append(-me(M2, t))\n",
        "  mu_moreau[2].append(-me(M3, t))\n",
        "  mu_moreau[3].append(me(M4, t))\n",
        "mu_moreau = np.array(mu_moreau).T\n",
        "\n",
        "p = figure(**(fig_kwargs | dict(title=f\"w:{w}, smooth:{j}\")))\n",
        "p.line(alpha_thresholds, mu_terms[:,0], line_color=\"red\")\n",
        "p.line(alpha_thresholds, mu_moreau[:,0], line_color=\"red\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, -mu_terms[:,1], line_color=\"green\")\n",
        "p.line(alpha_thresholds, -mu_moreau[:,1], line_color=\"green\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, -mu_terms[:,2], line_color=\"blue\")\n",
        "p.line(alpha_thresholds, -mu_moreau[:,2], line_color=\"blue\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, mu_terms[:,3], line_color=\"orange\")\n",
        "p.line(alpha_thresholds, mu_moreau[:,3], line_color=\"orange\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.line(alpha_thresholds, mu_terms.sum(axis=1), line_color=\"black\")\n",
        "p.line(alpha_thresholds, mu_moreau.sum(axis=1), line_color=\"black\", line_dash=\"dotted\", line_width=1.5)\n",
        "p.yaxis.minor_tick_line_alpha = 0\n",
        "show(p)"
      ],
      "id": "b6a3844a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Testing the moreau envelope \n",
        "from pbsig.linalg import prox_nuclear\n",
        "X = np.random.uniform(size=(10,10))\n",
        "X = X @ X.T\n",
        "\n",
        "from pbsig.linalg import soft_threshold\n",
        "t = 0.15\n",
        "ew, ev = np.linalg.eigh(X)\n",
        "assert np.isclose(sum(np.linalg.eigvalsh(ev @ np.diag(ew) @ ev.T)), sum(ew))\n",
        "assert np.isclose(sum(np.linalg.eigvalsh(ev @ np.diag(soft_threshold(ew, 0.15)) @ ev.T)), sum(soft_threshold(ew, 0.15)))\n",
        "P = ev @ np.diag(soft_threshold(ew, 0.15)) @ ev.T  #  proximal operator \n",
        "assert np.isclose(sum(np.linalg.eigvalsh(P)), sum(soft_threshold(ew, 0.15)))\n",
        "me = sum(soft_threshold(ew, 0.15)) + (1/(2*0.15))*np.linalg.norm(X - P, 'fro')**2\n",
        "P, mf, _ = prox_nuclear(X, t=t) # 35.36999221118293\n",
        "assert np.isclose(me, mf)\n",
        "\n",
        "\n",
        "A = np.random.uniform(size=(10,10))\n",
        "A = A @ A.T\n",
        "print(np.linalg.norm(A - X, 'fro')**2)\n",
        "ew_x, U =np.linalg.eigh(X)\n",
        "ew_v, V =np.linalg.eigh(A)\n",
        "S = np.diag(ew_x)\n",
        "D = np.diag(ew_v)\n",
        "\n",
        "np.trace(S**2) + np.trace(D**2) - 2*np.trace(V.T @ U @ S @ U.T @ V @ D)\n",
        "np.trace(S**2) + np.trace(D**2) - 2*np.trace(S**2 @ U.T @ X @ D @ X.T @ U)\n",
        "\n",
        "sum((np.diag(A) - np.diag(X))**2)\n",
        "sum((np.diag(A)**2 - np.diag(X)**2))\n",
        "\n",
        "\n",
        "\n",
        "from pbsig.linalg import moreau\n",
        "sum(moreau(ew, t))"
      ],
      "id": "77ec7bd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Investigate why the nuclear and moreau are so far away from the rank representations (and why they are biased)? This does not have anything to do with *w* apparently, as *w = 0* yields the same behavior. So let's just conclude the nuclear is not a good subtitute for the rank function. Instead, let's develop a proximal operator for the sign approximation function.\n"
      ],
      "id": "8c6a313d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pbsig.linalg import eigh_solver, eigvalsh_solver\n",
        "from pbsig.betti import mu_query_mat\n",
        "sf = sgn_approx(eps=1e-2, p=1.2)  \n",
        "LM = mu_query_mat(S, R=R, f=F[jj], p=1, form=\"array\")\n",
        "Y = LM[3].todense()\n",
        "#ew, ev = eigh_solver(Y)(Y)\n",
        "\n",
        "y_shape = Y.shape\n",
        "y = np.ravel(Y)\n",
        "def moreau_cost(y_hat: ArrayLike, t: float = 1.0):\n",
        "  Y_hat = y_hat.reshape(y_shape)\n",
        "  ew = np.maximum(np.real(np.linalg.eigvals(Y_hat)), 0.0) # eiegnvalues can be negative, so we project onto the PSD cone!\n",
        "  ew_yhat = sum(sf(ew)) \n",
        "  if t == 0.0: \n",
        "    return ew_yhat\n",
        "  return ew_yhat + (1/(t*2))*np.linalg.norm(Y_hat - Y, \"fro\")**2\n",
        "# ev @ np.diag(sf(ew)) @ ev.T\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "y_noise = y+np.random.uniform(size=len(y), low=0, high=0.01)\n",
        "w = minimize(moreau_cost, x0=y_noise, args=(0.01))\n",
        "Z = w.x.reshape(y_shape)\n",
        "print(f\"Status: {w.status}, total error: {np.linalg.norm(Z - Y, 'fro')}, Num it: {w.nit}, Num evals: {w.nfev} \\nMessage: {w.message}\")\n",
        "\n",
        "## Try a vector based optimization\n",
        "from scipy.optimize import minimize\n",
        "y_ew = np.linalg.eigvalsh(Y)\n",
        "def sgn_approx_cost(ew_hat: ArrayLike, t: float = 1.0):\n",
        "  return sum(sf(ew_hat)) + (1/(t*2)) * np.linalg.norm(sf(ew_hat) - sf(y_ew))**2\n",
        "y_ew_noise = y_ew + np.random.uniform(size=len(y_ew), low=0.0, high=0.50)\n",
        "w = minimize(sgn_approx_cost, x0=y_ew_noise, args=(0.5), tol=1e-15, method=\"Powell\")\n",
        "print(f\"Status: {w.status}, total error: {np.linalg.norm(y_ew - w.x)}, Num it: {w.nit}, Num evals: {w.nfev} \\nMessage: {w.message}\")\n",
        "\n",
        "\n",
        "\n",
        "eigvalsh_solver(Z)(Z)\n",
        "\n",
        "mu_query(S, R, f)\n",
        "solver = eigh_solver(x)\n",
        "ew, ev = solver(x)\n",
        "\n",
        "\n",
        "x0 \n",
        "\n",
        "# j = np.searchsorted(alpha_thresholds, 0.90)\n",
        "# mu = mu_query(S, R=np.append(R, 0.35), f=F[j], p=1, normed=True)\n",
        "# mu(smoothing=None, terms=False) # 1 \n",
        "# mu(smoothing=None, terms=True) # 8,  -8, -16,  17\n",
        "# mu(smoothing=sgn_approx(eps=1e-2, p=1.2), terms=False) # 1.0004954387928944\n",
        "# mu(smoothing=sgn_approx(eps=0.90, p=1.0), terms=False) # 0.5891569860030863\n",
        "# mu(smoothing=False, terms=True) #  8., -16., -16.,  24.\n",
        "\n",
        "# jj = np.searchsorted(alpha_thresholds, 1.15)\n",
        "# f=F[jj]\n",
        "# spectral_rank(EW[0])\n",
        "\n",
        "# mu = mu_query(S, R=np.append(R, 0.35), f=F[jj], p=1, normed=True)\n",
        "# mu(smoothing=False, terms=True)"
      ],
      "id": "77c31485",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mu_f.precompute(R=R, normed=False, progress=True)"
      ],
      "id": "d3d934b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use discrete vineyards to get an idea of what the\n",
        "\n",
        "# st = SimplexTree(complete_graph(X.shape\\[0\\]))\n",
        "\n",
        "# st.expand(2)\n",
        "\n",
        "# S = st\n",
        "\n",
        "N, M = 20, 24 SW = sliding_window(sw_f, bounds=(0, 12*np.pi)) d, tau = sw_parameters(bounds=(0,12*np.pi), d=M, L=6) #S = delaunay_complex(F(n=N, d=M, tau=tau)) X = SW(n=N, d=M, tau=tau) \\# r = enclosing_radius(X)\\*0.60 \\# S = rips_complex(X, r, 2) show(plot_complex(S, X\\[:,:2\\]))\n",
        "\n",
        "## Plot\n",
        "\n",
        "scatters = \\[\\] for t in np.linspace(0.50*tau, 1.50*tau, 10): X_delay = SW(n=N, d=M, tau=t) p = figure(width=150, height=150, toolbar_location=None) p.scatter(*pca(X_delay).T) scatters.append(plot_complex(S, pos=pca(X_delay), width=125, height=125)) show(row(*scatters))\n",
        "\n",
        "from pbsig.persistence import ph from pbsig.vis import plot_dgm K = filtration(S, f=flag_weight(X)) dgm = ph(K, engine=\"dionysus\") plot_dgm(dgm\\[1\\])\n",
        "\n",
        "from pbsig.betti import MuSignature, mu_query from pbsig.linalg import \\* R = np.array(\\[4, 4.5, 6.5, 7.5\\]) T_dom = np.append(np.linspace(0.87*tau, tau, 150, endpoint=False), np.linspace(tau, tau*1.12, 150, endpoint=False)) t_family = \\[flag_weight(SW(n=N, d=M, tau=t)) for t in T_dom\\]\n",
        "\n",
        "MU_f = mu_query(S, R=R, f=flag_weight(SW(n=N, d=M, tau=tau)), p=1, form=\"array\")\n",
        "\n",
        "Generate a noisy circle\n"
      ],
      "id": "2d0de3a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(1234)\n",
        "theta = np.linspace(0, 2*np.pi, 80, endpoint=False)\n",
        "circle = np.c_[np.sin(theta), np.cos(theta)]\n",
        "noise_scale = np.random.uniform(size=circle.shape[0], low=0.90, high=1.10)\n",
        "noise_scale = np.c_[noise_scale, noise_scale]\n",
        "noise = np.random.uniform(size=(10, 2), low=-1, high=1)\n",
        "X = np.vstack((circle*noise_scale, noise))\n",
        "\n",
        "## Plot the circle + noise \n",
        "p = figure(width=400, height=200)\n",
        "p.scatter(X[:,0], X[:,1], color=\"blue\")\n",
        "p.scatter(*noise.T, color=\"red\")\n",
        "show(p)"
      ],
      "id": "5fb9f8a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "````{=html}\n",
        "<!-- "
      ],
      "id": "98cc3edf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "alpha_thresholds = np.linspace(1e-12, max_scale*r, 100)\n",
        "vine = np.vstack([ph(F(alpha)[1], engine=\"dionysus\")[1] for alpha in alpha_thresholds])\n",
        "\n",
        "from bokeh.models import Range1d\n",
        "p = figure_dgm(vine[-1,:])\n",
        "p.scatter(np.ravel(vine['birth']), np.ravel(vine['death']))\n",
        "p.x_range = Range1d(0, max_scale*r)\n",
        "p.y_range = Range1d(0, max_scale*r)\n",
        "show(p)\n",
        "``` -->\n",
        "````"
      ],
      "id": "e626d7ef"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}