---
title: "Circle optimization"
format: html
jupyter: python3
---

```{python}
import numpy as np
from splex import *
from pbsig import * 
from pbsig.linalg import * 
from pbsig.vis import figure_complex
from bokeh.plotting import figure, show
from bokeh.io import output_notebook
from bokeh.layouts import row
output_notebook(verbose=False)
```

Generate a noisy circle

```{python}
np.random.seed(1234)
theta = np.linspace(0, 2*np.pi, 8, endpoint=False)
circle = np.c_[np.sin(theta), np.cos(theta)]

## Plot the circle + noise 
p = figure(width=300, height=300, match_aspect=True)
p.scatter(*circle.T, color="blue", size=12)
show(p)
```

For any choice of fixed radius $\epsilon \in \mathbb{R}_+$, we can construct a rips filtration $\mathcal{R}(X; \epsilon)$. For example:

```{python}
from pbsig.vis import *
eps_radius = 1.0
R = rips_filtration(circle, 1.0, p=2)
show(figure_complex(R, circle))
```

The homology of the rips complex is highly dependent on the scale parameter $\epsilon$. This shows that homology, in general, is not scale-invariant. To counter this, the typical approach is to vary $\epsilon \in [0, +\infty)$ and track the changes in the homology groups. Homology groups that seem to persist for over long contiguous subsets of $[0, +\infty)$ are thought to contain highly persistent cycles, i.e. homeomorphic cycles that are stable with respect to changes in the geometry. This is a bit of a misnomer, as the actual "cycles" generating the homology groups change quite often; indeed, each inclusion map $K_{i-1} \hookrightarrow K_{i}$ induces an entirely new coset.

Persistence is often summarized with a persistence diagram. 

```{python}

```

## Changing a different parameter 

Indeed, suppose we scale our circle by some scaling factor $\alpha \in [0,1]$, fixing $\epsilon$ arbitrarily.

```{python}
from bokeh.layouts import gridplot
from itertools import product
nr, nc, r = 2, 6, 0.5 # num rows, num columns, radius 
max_scale = 3.0
F = lambda alpha: (alpha*circle, rips_filtration(alpha*circle, r, p=2))
plots = [[None]*nc for r in range(nr)]
for alpha, (i,j) in zip(np.linspace(0.0, max_scale*r, nr*nc), product(range(nr), range(nc))):
  X, R = F(alpha)
  plots[i][j] = figure_complex(R, X, width=80, height=80, x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r))
show(gridplot(plots))
```

We have essentially the same effect, but in reverse: at first the complex is the full $n$-simplex, collapsed to trivial point in its embedding. As the complex expands, it changes from being a disk (trivial $H_1$) to a circle (non-trivial $H_1$) to $n$ disconnected points (trivial $H_1$). Essentially, rather than having an $\epsilon$-parameterized filtration over a fixed point cloud, we have an $\alpha$-parameterized family of rips filtrations $\{ \mathcal{R}_{\epsilon}(\alpha) \}_{\alpha \in A}$ of varying size but fixed filter. 

<!-- Suppose one is interested in finding the interval wherein the cycle generating the single homology group $H_1$ is the most "persistent" in $\alpha$. We could build a filtration in reverse to get inclusions... -->

```{python}
from pbsig.vis import plot_dgm, figure_dgm
from pbsig.persistence import ph 
# X, R = F(0.50)
# dgm = ph(R, engine="dionysus")[1]
# plot_dgm(dgm)

plots = [[None]*nc for r in range(nr)]
for alpha, (i,j) in zip(np.linspace(0.0, max_scale*r, nr*nc), product(range(nr), range(nc))):
  X, R = F(alpha)
  dgm = ph(R, engine="dionysus")
  dgm = dgm[1] if 1 in dgm.keys() else np.empty((0,2),dtype=[('birth', 'f4'), ('death', 'f4')])
  # figure_complex(R, X, width=100, height=100, x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r))
  plots[i][j] = figure_dgm(dgm, width=100, height=100) # x_range=(-max_scale*r,max_scale*r), y_range=(-max_scale*r,max_scale*r)
  plots[i][j].title = None
  plots[i][j].xaxis.axis_label = None
  plots[i][j].yaxis.axis_label = None
  # plots[i][j].xaxis.visible = False
show(gridplot(plots))
```

Observe we have a few "phase changes" that occur here. Initially, there is no $H_1$ class. As the the complex expands beyond the trivial point, a point appears representing the aforementioned cycle. Since the persistence diagram is stable, we know this point must appear first on the diagonal---it then travels further from the diagonal until the cycle is broken apart. In this situation, it becomes an _essential class_; we have not expanded the rips complex to a large enough $\epsilon$ to see triangles close up the cycle. The birth of the cycle grows infinitely as $\alpha \to \infty$. 

Suppose we wanted to determine the choices of $\alpha$ where this cycle existed. We can peek at these via a set of multiplicity queries:

```{python}
from pbsig.betti import mu_query
R = (0.5, 1.0, 1.5, 1.75)
S = simplicial_complex(faces(SimplexTree([np.arange(8)]), 2))
Q = [mu_query(S, R=R, f=flag_weight(alpha*circle), p=1, normed=False) for alpha in alpha_thresholds]

mult_H1 = [mu() for mu in Q]
p = figure(
  width=350, height=200, 
  title=f"Circle multiplicities for R={R}", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity"
)
p.step(alpha_thresholds, np.array(mult_H1, dtype=int))
p.yaxis.minor_tick_line_alpha = 0
show(p)
```

Equivalently, we can amortize the cost of creating so many matrices by re-using the results from previous computations. 
```{python}
from pbsig.betti import MuFamily
F = [flag_weight(alpha*circle) for alpha in alpha_thresholds]
mu_f = MuFamily(S, family=F, p=1, form="array")
mu_f.precompute(R=R, progress=True)

p = figure(
  width=350, height=200, 
  title=f"Circle multiplicities for R={R}", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity"
)
p.step(alpha_thresholds, np.array(mu_f(smoothing=None), dtype=int))
p.yaxis.minor_tick_line_alpha = 0
show(p)
```

Let's look at the constiutive terms that make up this multiplicity queries 
```{python}
p = figure(
  width=350, height=200, 
  title=f"Circle multiplicities for R={R}", 
  x_axis_label="alpha (scaling factor)", 
  y_axis_label="Constititive ranks"
)
mu_terms = mu_f(smoothing=None, terms=True).T
p.step(alpha_thresholds, mu_terms[:,0], line_color="orange")
p.step(alpha_thresholds, -mu_terms[:,1], line_color="blue")
p.step(alpha_thresholds, -mu_terms[:,2], line_color="red")
p.step(alpha_thresholds, mu_terms[:,3], line_color="green")
p.step(alpha_thresholds, mu_f(smoothing=None), line_color="black")
p.yaxis.minor_tick_line_alpha = 0
show(p)
```

Now, let's look at a continuous relaxation of both the multiplicity function and its constitituive terms. 




```{python}
## constituive terms
mu_f.precompute(R=R, w=0.35, normed=False, progress=True)
mu_terms = mu_f(smoothing=None, terms=True).T
mu_terms_moreau = mu_f(smoothing=moreau(), terms=True).T
mu_terms_nuclear = mu_f(smoothing=False, terms=True).T
mu_terms_sgn_approx = mu_f(smoothing=sgn_approx(eps=1e-3, p=1.5), terms=True).T
q = figure(
  width=450, height=300, 
  title=f"Circle multiplicities for R={R}", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity"
)
q.yaxis.minor_tick_line_alpha = 0
q.line(alpha_thresholds, -mu_terms_moreau[:,0], line_color = "red", legend_label="Moreau")
q.line(alpha_thresholds, -mu_terms_nuclear[:,0], line_color = "orange", legend_label="Nuclear")
q.line(alpha_thresholds, -mu_terms_sgn_approx[:,0], line_color = "blue", legend_label="SgnApprox")
q.step(alpha_thresholds, -mu_terms[:,0], line_color = "black", legend_label="Rank")
q.legend.label_text_font_size = '4pt'
q.legend.padding = 0
q.legend.spacing = 0

mu_f.precompute(R=R, w=0.35, normed=True, progress=True)
mu_terms = mu_f(smoothing=None, terms=True).T
mu_terms_moreau = mu_f(smoothing=moreau(), terms=True).T
mu_terms_nuclear = mu_f(smoothing=False, terms=True).T
mu_terms_sgn_approx = mu_f(smoothing=sgn_approx(eps=1e-3, p=1.5), terms=True).T
p = figure(
  width=450, height=300, 
  title=f"Circle multiplicities for R={R}", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity"
)
p.yaxis.minor_tick_line_alpha = 0
p.line(alpha_thresholds, -mu_terms_moreau[:,0], line_color = "red", legend_label="Moreau")
p.line(alpha_thresholds, -mu_terms_sgn_approx[:,0], line_color = "blue", legend_label="SgnApprox")
p.step(alpha_thresholds, -mu_terms[:,0], line_color = "black", legend_label="Rank")
p.line(alpha_thresholds, -mu_terms_nuclear[:,0], line_color = "orange", legend_label="Nuclear")
p.legend.label_text_font_size = '4pt'
p.legend.padding = 0
p.legend.spacing = 0

from bokeh.layouts import row
show(row([q, p]))
```

The weighted combinatorial laplacian is simply unstable whenever $w > 0$, due to the face that $1/\epsilon$ can produce arbitrarily large values as $\epsilon \to 0^+$. This is not a problem for the normalized laplacian, as the spectrum is always bounded in the range $[0, p+2]$. From now on, let's only consider the normalized weighted combinatorial laplacian. 

```{python}
mu_f.precompute(R=R, w=0.35, normed=True, progress=True)
figs = []
fig_kwargs = dict(width=250, height=150,title=f"Circle multiplicities", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity")
for ef in [None, False, sgn_approx(eps=1e-2, p=1.2), moreau(t=0.15)]:
  mu_terms = mu_f(smoothing=ef, terms=True).T
  p = figure(**fig_kwargs)
  p.line(alpha_thresholds, mu_terms[:,0], line_color="orange")
  p.line(alpha_thresholds, -mu_terms[:,1], line_color="blue")
  p.line(alpha_thresholds, -mu_terms[:,2], line_color="red")
  p.line(alpha_thresholds, mu_terms[:,3], line_color="green")
  p.line(alpha_thresholds, mu_terms.sum(axis=1), line_color="black")
  p.yaxis.minor_tick_line_alpha = 0
  figs.append(p)

show(row(figs))
# mu_query(S, R=np.append(R, 0.35), f=F[j], p=1, normed=True)(smoothing=False, terms=True)
```

```{python}
mu_f.precompute(R=R, normed=True, progress=True)
mu_terms = mu_f(smoothing=None)
mu_terms_moreau = mu_f(smoothing=moreau())
mu_terms_nuclear = mu_f(smoothing=False)
mu_terms_sgn_approx = mu_f(smoothing=sgn_approx(eps=1e-3, p=1.5))
p = figure(
  width=450, height=300, 
  title=f"Circle multiplicities for R={R}", x_axis_label="alpha (scaling factor)", y_axis_label="multiplicity"
)
p.yaxis.minor_tick_line_alpha = 0
p.line(alpha_thresholds, mu_terms_moreau, line_color = "red", legend_label="Moreau")
p.line(alpha_thresholds, mu_terms_sgn_approx, line_color = "blue", legend_label="SgnApprox")
p.step(alpha_thresholds, mu_terms, line_color = "black", legend_label="Rank")
p.line(alpha_thresholds, mu_terms_nuclear, line_color = "orange", legend_label="Nuclear")
p.legend.label_text_font_size = '4pt'
p.legend.padding = 0
p.legend.spacing = 0
show(p)
```



```{python}
mu_f.precompute(R=R, normed=False, progress=True)

```



Use discrete vineyards to get an idea of what the

# st = SimplexTree(complete_graph(X.shape\[0\]))

# st.expand(2)

# S = st

N, M = 20, 24 SW = sliding_window(sw_f, bounds=(0, 12*np.pi)) d, tau = sw_parameters(bounds=(0,12*np.pi), d=M, L=6) #S = delaunay_complex(F(n=N, d=M, tau=tau)) X = SW(n=N, d=M, tau=tau) \# r = enclosing_radius(X)\*0.60 \# S = rips_complex(X, r, 2) show(plot_complex(S, X\[:,:2\]))

## Plot

scatters = \[\] for t in np.linspace(0.50*tau, 1.50*tau, 10): X_delay = SW(n=N, d=M, tau=t) p = figure(width=150, height=150, toolbar_location=None) p.scatter(*pca(X_delay).T) scatters.append(plot_complex(S, pos=pca(X_delay), width=125, height=125)) show(row(*scatters))

from pbsig.persistence import ph from pbsig.vis import plot_dgm K = filtration(S, f=flag_weight(X)) dgm = ph(K, engine="dionysus") plot_dgm(dgm\[1\])

from pbsig.betti import MuSignature, mu_query from pbsig.linalg import \* R = np.array(\[4, 4.5, 6.5, 7.5\]) T_dom = np.append(np.linspace(0.87*tau, tau, 150, endpoint=False), np.linspace(tau, tau*1.12, 150, endpoint=False)) t_family = \[flag_weight(SW(n=N, d=M, tau=t)) for t in T_dom\]

MU_f = mu_query(S, R=R, f=flag_weight(SW(n=N, d=M, tau=tau)), p=1, form="array")

Generate a noisy circle

```{python}
np.random.seed(1234)
theta = np.linspace(0, 2*np.pi, 80, endpoint=False)
circle = np.c_[np.sin(theta), np.cos(theta)]
noise_scale = np.random.uniform(size=circle.shape[0], low=0.90, high=1.10)
noise_scale = np.c_[noise_scale, noise_scale]
noise = np.random.uniform(size=(10, 2), low=-1, high=1)
X = np.vstack((circle*noise_scale, noise))

## Plot the circle + noise 
p = figure(width=400, height=200)
p.scatter(X[:,0], X[:,1], color="blue")
p.scatter(*noise.T, color="red")
show(p)
```

<!-- 

```{python}
alpha_thresholds = np.linspace(1e-12, max_scale*r, 100)
vine = np.vstack([ph(F(alpha)[1], engine="dionysus")[1] for alpha in alpha_thresholds])

from bokeh.models import Range1d
p = figure_dgm(vine[-1,:])
p.scatter(np.ravel(vine['birth']), np.ravel(vine['death']))
p.x_range = Range1d(0, max_scale*r)
p.y_range = Range1d(0, max_scale*r)
show(p)
``` -->