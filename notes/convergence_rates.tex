\documentclass[10pt]{article}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{url}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amsmath,blkarray,booktabs,bigstrut}

\usepackage{etoolbox}
\let\bbordermatrix\bordermatrix
\patchcmd{\bbordermatrix}{8.75}{4.75}{}{}
\patchcmd{\bbordermatrix}{\left(}{\left[}{}{}
\patchcmd{\bbordermatrix}{\right)}{\right]}{}{}

\makeatletter
\newif\if@borderstar
\def\bordermatrix{\@ifnextchar*{%
\@borderstartrue\@bordermatrix@i}{\@borderstarfalse\@bordermatrix@i*}%
}
\def\@bordermatrix@i*{\@ifnextchar[{\@bordermatrix@ii}{\@bordermatrix@ii[()]}}
\def\@bordermatrix@ii[#1]#2{%
\begingroup
\m@th\@tempdima8.75\p@\setbox\z@\vbox{%
\def\cr{\crcr\noalign{\kern 2\p@\global\let\cr\endline }}%
\ialign {$##$\hfil\kern 2\p@\kern\@tempdima & \thinspace %
\hfil $##$\hfil && \quad\hfil $##$\hfil\crcr\omit\strut %
\hfil\crcr\noalign{\kern -\baselineskip}#2\crcr\omit %
\strut\cr}}%
\setbox\tw@\vbox{\unvcopy\z@\global\setbox\@ne\lastbox}%
\setbox\tw@\hbox{\unhbox\@ne\unskip\global\setbox\@ne\lastbox}%
\setbox\tw@\hbox{%
$\kern\wd\@ne\kern -\@tempdima\left\@firstoftwo#1%
\if@borderstar\kern2pt\else\kern -\wd\@ne\fi%
\global\setbox\@ne\vbox{\box\@ne\if@borderstar\else\kern 2\p@\fi}%
\vcenter{\if@borderstar\else\kern -\ht\@ne\fi%
\unvbox\z@\kern-\if@borderstar2\fi\baselineskip}%
\if@borderstar\kern-2\@tempdima\kern2\p@\else\,\fi\right\@secondoftwo#1 $%
}\null \;\vbox{\kern\ht\@ne\box\tw@}%
\endgroup
}
\makeatother
%\bordermatrix[{[]}]{%
%            & i & j \cr
%          i & \phantom{-}1 & -1 \cr
%          j & -1 & \phantom{-}1 }

\title{\vspace{-2.0em} Notes about convergence rate\vspace{-0.5em}}
\author{Matt Piekenbrock}
\date{}

\begin{document} \vspace{-2em} \maketitle \vspace{-2em}
\noindent If the value $x^\ast$ that a sequence $\{x_n\} = x_1, x_2, \dots, x_n$ approaches exists, then $\{x_n\}$ is called \emph{convergent}. Moreover, if there exist real numbers $\mu \leq 1$ and $\alpha \geq 1$ such that:
$$ \lim_{n \to \infty} \frac{ \lvert x_{n+1} - x^\ast \rvert }{ \lvert x_n - x^\ast \rvert^\alpha } = \mu $$
then sequence is convergent, and the value of $\alpha$ is called the \emph{rate of convergence}. 
When $\mu \in (0,1)$, the
When $\alpha = 1$, $2$, and $3$, we say the sequence exhibits \emph{linear}, \emph{quadratic}, and \emph{cubic} convergence, respectively. 
A sequence with rate $1 < \alpha < 2$ is said to converge \emph{superlinearly}.

% sublinear?


% https://www.math-cs.gordon.edu/courses/ma342/handouts/rate.pdf

\section{Spectral Sparsifiers \& Effective Resistance}
Given a weighted undirected graph $G = (V, E, w)$ with $w: E \to \mathbb{R}_+$, denote with $L_G$ its weighted \emph{graph Laplacian} $L_G = D - W$, where $D = \mathrm{diag}(\mathrm{deg}^w(v_1), \mathrm{deg}(v_2), \dots, \mathrm{deg}(v_n))$ is a diagonal (weighted) degree matrix and $W$ is the weighted adjacency matrix satisfying $W[i,j] = -w_{ij}$ for $i \neq j$ and $v_i \sim v_j$. 
An intuitive goal is to choose a sparse subgraph $H = (V, E')$ with $E' \subseteq E$ satisfying: 
$$ (1 - \epsilon) L_G \preceq L_H \preceq (1 + \epsilon) L_G \quad \Leftrightarrow \quad (1-\epsilon)x^T L_G x \leq x^T L_H x \leq (1+\epsilon)x^T L_G x$$
If we can find a subgraph $H$ satisfying this, then $L_H$ is said to be an \emph{$\epsilon$-spectral sparsifier} of $G$. Such sparsifiers are naturally very appealing in that they satisfying the following properties: 
\begin{enumerate}
	\item (Cut approximation) The weight of every cut $w_G(E(S, S'))$ is within $1 \pm \epsilon$ of $L_H(E(S, S'))$
	\item ($\kappa$-approximation) $(1-\epsilon)^{-1}H$ is a $(1+\epsilon)(1-\epsilon)^{-1}$-approximation of $G$; $H$ is called a \emph{$\kappa$-approximation} of $G$ if:  
	$$L_G \preceq L_H \preceq \kappa L_G \quad \Leftrightarrow \quad \kappa^{-1} L_G^{+} \preceq L_H^{+} \preceq L_G^{+} $$
	\item (Spectral approximation) If $\Lambda(L_G) = \{\lambda_1, \lambda_2, \dots, \lambda_n\}$ and $\Lambda(L_H) = \{\lambda_1', \lambda_2', \dots, \lambda_n'\}$, then $(1-\epsilon) \lambda_k' \leq \lambda_k \leq (1+\epsilon) \lambda_k'$
%	\item (Edge sparsity) $\lvert E' \rvert \sim O(n \log(n) \cdot \epsilon^{-1})$ 
\end{enumerate}
Since the definition does not explicitly bound the size of $E'$, clearly a subgraph $H \subseteq G$ always exists. It's not immediately clear whether one can obtain sparser graphs $H$ with e.g. edge sparsities $\lvert E' \rvert \sim O(n \log(n) \cdot \epsilon^{-1})$.
Surprisingly, Spielman showed a positive existential result towards this direction: every connected, \emph{unweighted} graph $G = (V, E)$ admits a \emph{weighted} subgraph $H = (V, E', w')$ that is an $\epsilon$-spectral sparsifier, and the number of edges of these sparsifiers $\lvert E'\rvert$ is the order of $O(\epsilon^{-2} n \log n)$. Moreover, they gave a simple randomized sampling algorithm to obtain such sparsifiers. 

The idea of their approach is as follows: Let $L_e$ denote its restriction to edge $e \in E$, i.e. the $n \times n$ matrix with $L_e[i,i] = L_e[i,j]  = 1$ and $L_e[i,i] = L_e[j,j]  = -1$. This matrix is given by the outer product $L_e = (\xi_i - \xi_j)(\xi_i - \xi_j)^T$, where $\xi_{i}$ is the characteristic vector with a $1$ in the $i$-th component and $0$ otherwise. Observe that: 
$$ L_G = \sum\limits_{e \in E} w_e L_e$$
Now, suppose we have edge probabilites $\{p_e\}_{e \in E}$ satisyfing $\sum_{e \in E} p_e = 1$ and we construct $H$ by sampling $k$ edges iid from $E$ with respect to these probabilities. By definition of epxectation, we have:
$$ \mathbb{E}[L_H] = \sum\limits_{e \in E} p_e \cdot \frac{1}{k p_e} L_e = \sum\limits_{e \in E} \frac{1}{k} L_G$$
Thus $L_H$ approximates $L_G$ via a sum of iid random matrices. By utilizing random matrix theory, one may readily apply concentration inequalities, such as Chernoff bounds, to bound the degree of the approximation. In particular, if $L_H^{(i)} \preceq \delta \mathbb{E}[L_H^{(i)}]$ with probability $1$ for any $\delta \geq 1$, then with $k \sim O(\delta \cdot \epsilon^{-2} \cdot n \log n)$ edges sampled, one has: 
$$ P(L_H \subset_{\epsilon} L_G) \geq 1 - 2ne^{-\epsilon^{2} k} / 4\delta$$ 

% https://www.cs.cmu.edu/~jkoutis/papers/stacs239koutis.pdf
Computing the effective resistance of a given edge requires---almost by definition---the solution of a linear system on the graph Laplacian.

\end{document}
